---
title: "Резервные копии для озабоченных"
date: 2014-09-07T14:20:40-05:00
draft: false
tags: ["технические темы"]
slug: remote-backup-mac
---

Перефразируя известную фразу, начну с поучительного: *Пользователи компьютеров делятся на тех кто еще не делает бэкапы, и тех кто уже делает*.

Добавлю от себя, что даже если вам и кажется, что все это лишнее и на вашем компьютере ничего такого уж ценного нет, то в день (а он рано или поздно наступит) когда вы потеряете все свои данные ваше мнение может сильно измениться. И чтоб такой день не наступил, все разумные пользователи нормальных компьютеров **должны делать резервные копии**. Кроме того, они должны их делать регулярно и автоматически.


Современные ОС тоже пытаются донести до вас эту простую мысль и оснащаются подобными средствами "из коробки". Я не уверен, что сейчас с бэкапами в самой-популярной-системе, но в моем мире маков добавлeние TM (машины времени/Time Machine) в свое время сильно популяризировало эту идею и довело реализацию создания и восстановления резервных копий до превосходного состояния "все в один клик".

Однако, у такого бэкапа естъ существенный недостаток - он находится географически близко к вашему компьютеру. Как правило это просто внешний диск подключенный по USB.  Несомненно, такой вариант отлично подходит для восстановления после сбоев, однако в случае чего-то плохого в офлайновом мире у вас есть шанс потерять одновременно - и основной компьютер и его резервную копию. Вариантов этого "чего-то плохого" много, например пожар/наводнение, торнадо, ядерный взрыв или нашествие инопланетян. Ну и кроме того не стоит отбрасывать варианты попроще, типа ограбления/воровства, когда злоумышленник может умыкнуть всю вашу технику включая и диск с резервными копиями.

Т.е. локальные резервные копии это хорошо, правильно, но мало. Всякий пользователь, озабоченный сохранностью своих данных просто обязан держать копии где-то вне дома. И, поскольку мы озабоченны не только сохранностью, но и приватностью - эти удаленные бэкапы должны быть доступны только для вас и зашифрованы тем или иным образом. Решений этой проблемы есть несколько, вот некоторые из них:

* Создание еженедельных/ежемесячных копий всего диска вручную, и доставка этих дисков в надежное место для хранения. Именно так и делает один из моих коллег, неустанно отвозя диски теще. Проблем у этого способа масса - во первых, это ручной процесс, во вторых надо часто видеть тещу, а в последних надо много дисков в ротации, чтоб была возможность гибкого восстановления. Кроме того, актуальность таких полных бэкапов не будет слишком уж хорошей если не проводить всю это процедуру каждый день.

* Использование специальных сетевых (облачных) сервисов для ведения резервных копий. Один из самых известных в этой категории это [CrashPlan](http://www.code42.com/crashplan/). За $4/месяц они продают вам сервис с неограниченным обьемом удаленного бэкапа и прилагают к этому вполне симпатичную программу, которая может это все делать автоматически. Еще один пример из этой же категории это [Backblaze](https://www.backblaze.com) который за $5/мес предоставляет тот же неограниченный размер и еще более человеческую программу. В обоих случаях обещается приватность данных и шифрование. Из моего собственного опыта я пришел к выводу, что оба этих сервиса не подходят для создания реально больших резервных копий. Проблему "неограниченного облачного диска" они решают ограничением скорости и попытка залить туда нечто большое превращается в совершенное непотребство. В моем случае я попытался сделать бэкап 300Г папки и после 2х недель ожидания и 10% залитого просто плюнул на это дело. Похоже, что они снижают скорость в процессе заливки чтоб ограничить этот теоретический "unlimited" до чего-то практического. Либо это не злой умысел, но просто их каналы сильно перегружены. Не знаю, но в конечном итого оба для меня оказались неприемлемыми. Кроме того, есть определенный риск, что их бизнес модель окажется несостоятельной и они закроют лавочку в один прекрасный день, а мы потеряем все свои резервные копии.

* Подключение своего собственного резервного диска к интернету вне дома. Таких вариантов можно купить в готовом виде, например [WD My Cloud](http://www.wdc.com/en/products/products.aspx?id=1140) либо собрать самому из диска и завалявшегося в закромах компьютера. Конечно, надо место где все это будет стоять и подключаться к интернету. Я, долгое время, использовал подобный удаленный сетевой диск, поставив в офисе [Raspberry Pi](http://p.umputun.com/p/2012/12/27/raspberry-pi/) с внешним диском и использовал [BitTorrent Sync](http://p.umputun.com/p/2013/06/18/ieshchie-odno/) для автоматической синхронизации. Все это худо-бедно работало, но восторга не вызывало. Скорость интернета в конторе у меня не самая высокая, особенно на заливку. И надежность этой связки тоже была не фонтан - то свет потухнет, то коллега случайно провод вытянет, то RPi глпюкнет.

* Использование облачных хранилищ от известных игроков этого рынка - Amazon, Google и DropBox. Вот именно в эту сторону стоит посмотреть повнимательней, чем мы сейчас и займемся.

Резкое падение цен на облачные "диски" сделало привлекательным их использование для таких резервных копий. За $10/мес и Google и DropBox продает целый терабайт места. У амазона теоретически этот же терабайт в Glacier тоже обойдется в $10/мес, но там все сложнее и с пониманием реальной цены и с восстановлением, так что я бы не рекомендовал.

Определившись с выбором (я выбрал Гугл) надо подобрать программу для автоматизации процесса. Для меня тут особого выбора не было, т.к. с начала года я открыл для себя весьма достойный [Arq](http://www.haystacksoftware.com/arq/) который позволяет создавать резервные копии на удаленные места через разные пути (FTP, SFTP, Google, Amazon и прочие), полностью автоматизирует процедуру и защищает данные шифрованием до того, как они покидают ваш компьютер.

Сам Arq несколько ... аскетичен и его внешний вид восторгов не вызывает. Однако, добавление новых сетевых бэкапов и их восстановление довольно просто и работает именно так, как в этом видео.

<iframe width="640" height="480" src="//www.youtube.com/embed/Eo7zbwnaUpk" frameborder="0" allowfullscreen></iframe>

Что касается скорости, то заливка данных в Google Drive через Arq показывает вполне адекватные цифры. Мне удалось залить 300Г примерно за 3 дня и никакого уменьшения скорости в процессе я не заметил. После начальной загрузки Arq продолжает бэкапить данные, заливая только новые файлы. У меня это настроено на ежедневный режим, начинается в 3 часа ночи и к утру все уже готово. На практике, это решение как раз из серии "настроил-забыл". Пока у меня не возникло практической надобности восстановить эти данные, но конечно я проверил как оно работает. И да, оно работает.

![](/images/posts/9znqo-20140907-171902.png)

Сам Arq стоит $40, что конечно дороговато, но я заплатил и вам советую. Программа работает надежно, предсказуемо и ничему не мешает. Даже в процессе создания копий или восстановления, ее влияние на производительность компьютера практически незаметно. Настроек там немного, но они позволяют главное - выбрать режим создания копий, выбрать максимальный размер занимаемого места в облаке и добавить любые папки, как локальные так и сетевые в набор для бэкапа. Кроме того, можно использовать несколько разных облаков и, например, хранить часть данных в Google Drive а другую часть в Amazon S3. К сожалению, пока нет правильного способа добавить DropBox в качестве пункта назначения, но я донес это пожелание до автора программы и есть надежда, что скоро такая возможность появится.

![](/images/posts/7o4rj-20140907-171833.png)

И завершу на поучительной ноте, чисто для симметрии - **делайте бэкапы, хоть какие-то**. Не можете удаленные - делайте локальные. Не можете автоматические - делайте ручные. Любой, самый завалящий бэкап гораздо лучше чем его полное отсустствие.

*Если у вас есть любимые способы создания резервных копий, как локальных так и удаленных - поделитесь в комментариях, будет всем полезно.*
